{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "# create SparkContext if sc doesn't exist.\n",
    "try:\n",
    "    sc\n",
    "except NameError:\n",
    "    sc =SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark session\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Word Count\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec is a great way to represent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "# in future I plan to use it. But this time I only use tf-idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from train.csv. No other data is used for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.csv(\"finalproject/data/train.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------------------+--------------------+---------+\n| id|product_uid|       product_title|         search_term|relevance|\n+---+-----------+--------------------+--------------------+---------+\n|  2|     100001|Simpson Strong-Ti...|       angle bracket|      3.0|\n|  3|     100001|Simpson Strong-Ti...|           l bracket|      2.5|\n|  9|     100002|BEHR Premium Text...|           deck over|      3.0|\n| 16|     100005|Delta Vero 1-Hand...|    rain shower head|     2.33|\n| 17|     100005|Delta Vero 1-Hand...|  shower only faucet|     2.67|\n| 18|     100006|Whirlpool 1.9 cu....|      convection otr|      3.0|\n| 20|     100006|Whirlpool 1.9 cu....|microwave over stove|     2.67|\n| 21|     100006|Whirlpool 1.9 cu....|          microwaves|      3.0|\n| 23|     100007|Lithonia Lighting...|     emergency light|     2.67|\n| 27|     100009|House of Fara 3/4...|             mdf 3/4|      3.0|\n| 34|     100010|Valley View Indus...|        steele stake|     2.67|\n| 35|     100011|Toro Personal Pac...|briggs and stratt...|      3.0|\n| 37|     100011|Toro Personal Pac...|            gas mowe|      3.0|\n| 38|     100011|Toro Personal Pac...|         honda mower|      2.0|\n| 48|     100012|Hampton Bay Caram...|hampton bay chest...|     2.67|\n| 51|     100013|InSinkErator Sink...|            disposer|     2.67|\n| 65|     100016|Sunjoy Calais 8 f...|        grill gazebo|      3.0|\n| 69|     100017|MD Building Produ...|         door guards|      1.0|\n| 75|     100017|MD Building Produ...|metal plate cover...|     1.67|\n| 81|     100017|MD Building Produ...|      radiator grate|     2.33|\n+---+-----------+--------------------+--------------------+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use HashingTF to calculate the topic words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=2, product_uid=100001, product_title=u'Simpson Strong-Tie 12-Gauge Angle', search_term=u'angle bracket', relevance=3.0, product_title_words=[u'simpson', u'strong-tie', u'12-gauge', u'angle'], search_words=[u'angle', u'bracket'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "tokenizer_title = Tokenizer(inputCol=\"product_title\", outputCol=\"product_title_words\")\n",
    "tokenizer_query = Tokenizer(inputCol=\"search_term\", outputCol=\"search_words\")\n",
    "\n",
    "wordsData = tokenizer_title.transform(train_data)\n",
    "wordsData = tokenizer_query.transform(wordsData)\n",
    "wordsData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(product_title_words_rawFeatures=SparseVector(262144, {5505: 1.0, 26505: 1.0, 54375: 1.0, 159707: 1.0}), search_words_rawFeatures=SparseVector(262144, {54375: 1.0, 228696: 1.0})),\n Row(product_title_words_rawFeatures=SparseVector(262144, {5505: 1.0, 26505: 1.0, 54375: 1.0, 159707: 1.0}), search_words_rawFeatures=SparseVector(262144, {213302: 1.0, 228696: 1.0}))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashingTF_pro = HashingTF(inputCol=\"product_title_words\", outputCol=\"product_title_words_rawFeatures\")\n",
    "hashingTF_qeury = HashingTF(inputCol=\"search_words\", outputCol=\"search_words_rawFeatures\")\n",
    "featurizedData = hashingTF_pro.transform(wordsData)\n",
    "featurizedData = hashingTF_qeury.transform(featurizedData)\n",
    "featurizedData.select('product_title_words_rawFeatures','search_words_rawFeatures').take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=2, product_uid=100001, product_title=u'Simpson Strong-Tie 12-Gauge Angle', search_term=u'angle bracket', relevance=3.0, product_title_words=[u'simpson', u'strong-tie', u'12-gauge', u'angle'], search_words=[u'angle', u'bracket'], product_title_words_rawFeatures=SparseVector(262144, {5505: 1.0, 26505: 1.0, 54375: 1.0, 159707: 1.0}), search_words_rawFeatures=SparseVector(262144, {54375: 1.0, 228696: 1.0}), features_prod=SparseVector(262144, {5505: 5.4076, 26505: 7.0696, 54375: 5.4697, 159707: 5.5326}), features_query=SparseVector(262144, {54375: 6.2499, 228696: 5.8897}))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_prod = IDF(inputCol=\"product_title_words_rawFeatures\", outputCol=\"features_prod\")\n",
    "idfModel = idf_prod.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "idf_query = IDF(inputCol=\"search_words_rawFeatures\", outputCol=\"features_query\")\n",
    "idfModel = idf_query.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(rescaledData)\n",
    "rescaledData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a LinearRegression model. \n",
    "* input data : two tf-idf Vector\n",
    "* output data : score range from 0 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.sql.functions import udf\n",
    "# rescaledData.show()\n",
    "# merge two vector into one feature vector\n",
    "vs = VectorAssembler(inputCols=['features_prod','features_query'],outputCol='features')\n",
    "rescaledData = vs.transform(rescaledData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features', regParam=0.3, elasticNetParam=0.8,labelCol='relevance',maxIter=1000,)\n",
    "(trainingData, testData) = rescaledData.randomSplit([0.7, 0.3])\n",
    "model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (524288,[],[])\nIntercept: 2.3826735447\nnumIterations: 1\nobjectiveHistory: [0.4999903398442797]\nRMSE: 0.533875\nr2: -0.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulate the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.534227\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"relevance\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(relevance=3.0, prediction=2.382673544697543)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.select('relevance','prediction').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, product_title: string, search_term: string, relevance: double, product_title_words: array<string>, search_words: array<string>, product_title_words_rawFeatures: vector, search_words_rawFeatures: vector, features_prod: vector, features_query: vector, features: vector]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "* The result is pretty bad. Later I plan to use other methods to train the model.\n",
    "* Next week I will use Word2Vec to train the model. \n",
    "* Also I plan to use other data like attributes and product description to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import Row\n",
    "\n",
    "# temp = rescaledData.rdd.map(lambda x:Row(x['features_query'])).toDF()\n",
    "# tempdata = rescaledData.take(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = rescaledData.sample(False,0.01).rdd.map(lambda x: Row(float(x['features_query'].squared_distance(x['features_prod']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp1.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3106d06b6e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}